# Manipulated Reality: Real-time Video and Audio Analysis for Deepfake Detection

## Abstract
Deepfake technology is rapidly advancing, blurring the lines between reality and fabrication. Our project aims to develop a system that can analyze video and audio content to detect deepfakes in real-time. By leveraging complex algorithms and machine learning models, we aim to provide a tool that can help maintain the integrity of digital communications and the security of information on the Internet.

## Table of Contents
1. [Introduction](#introduction)
2. [Background and Related Work](#background-and-related-work)
3. [Expected Achievements](#expected-achievements)
4. [Engineering Process](#engineering-process)
5. [Verification](#verification)
6. [Success Criteria](#success-criteria)
7. [References](#references)

## Introduction
Deepfake technology is a significant challenge to the dependability of face recognition systems and the integrity of information on the Internet. Faces play an important role in human interactions and biometrics-based person identification. Therefore, face manipulations can critically disrupt trust in digital communications and security applications. Our project aims to develop a system that can analyze video and audio content to detect deepfakes in real-time.

## Background and Related Work
### Deepfake Creation
Deepfake creation involves the use of neural networks, such as Generative Adversarial Networks (GANs) and Autoencoders (AEs). These networks generate believable visual, auditory, and video fakes by modifying pre-existing source content or generating entirely new content where an individual is depicted performing or uttering something they did not perform or say.

### Deepfake Detection
Deepfake detection is done by analyzing multiple regions of a personâ€™s face and detecting irregularities, deformed facial expressions, blurry areas around generated areas, etc. The analysis is done by various algorithms such as image processing, image segmentation, face detection, and pattern recognition.

### Existing Solutions
Existing solutions include eye-based deepfake detection, mouth-based deepfake detection, and technical deepfake detection. Audio-based deepfake detection uses Bi-Spectral and Cepstral statistics on the audio signals.

## Expected Achievements
Our primary objective is to develop three machine learning models designed to identify Deepfake video and audio files. We plan on merging all three models and make them interact with each other using a percentage estimator. The proposed system will feature an intuitive user interface that allows the uploading of media files and provides the user with a probability estimate, indicating the likelihood of the uploaded content being a Deepfake.

## Engineering Process
The engineering process will involve the following steps:
- **Research**: Comprehending the mechanisms underlying the creation of deepfakes and their potential impacts on societal norms.
- **Dataset Collection**: Collecting an extensive dataset to enhance the precision of our model.
- **Model Training**: Training the model using the collected dataset.
- **User Interface Development**: Developing a user-friendly interface for users to upload and analyze their media files.

## Verification
The success of the project will be measured by the detection rate of deepfakes, aiming to stay within the range of  60%-95% using a broader range of training datasets and multiple ML models.

## Success Criteria
The success criteria for our project are as follows:
- Detection rate: Aiming for a detection rate of  60%-95%.
- Model adaptability: The model should analyze data only when a face or speech is detected.

## References
Please refer to the [References](#references) section for a list of sources used in this project.
